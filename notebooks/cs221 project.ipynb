{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sqlite3\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport sklearn as sk \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sqlite3 import Error\nfrom sklearn.utils import shuffle\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import balanced_accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\ndatabase = \"../input/FPA_FOD_20170508.sqlite\"\ntest = pd.read_parquet(\"../input/wildfires-testset/test-wildfires.parquet\")\ntrain = pd.read_parquet(\"../input/wildfirestrain/train-wildfires.parquet\")\nprint (train[['STAT_CAUSE_CODE', 'STAT_CAUSE_DESCR']].drop_duplicates())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"##state included, No cont date, unnormalized, logistic and random forest\n\ndef create_connection(db_file):\n    \"\"\" create a database connection to the SQLite database\n        specified by the db_file\n    :param db_file: database file\n    :return: Connection object or None\n    \"\"\"\n    try:\n        conn = sqlite3.connect(db_file)\n        return conn\n    except Error as e:\n        print(e)\n \n    return None\n \n\n\n\n# create a database connection\n#conn = create_connection(database)\n\"\"\"\ncur = conn.cursor()\ncur.execute('SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES')\nprint(cur.fetchall())\n\"\"\"\n#print(train.columns)\n#df = pd.read_sql_query(\"SELECT STAT_CAUSE_CODE,FIRE_YEAR,LATITUDE,LONGITUDE,DISCOVERY_DATE,FIRE_SIZE FROM 'Fires' WHERE STATE='CA' \", conn)\n#df = df[df.CONT_DATE.notna()]\n#df3 = pd.read_sql_query(\"SELECT STAT_CAUSE_CODE, FIRE_YEAR, LATITUDE, LONGITUDE, DISCOVERY_DATE,FIRE_SIZE, STATE FROM Fires\", conn)\ndf3 = train[['STAT_CAUSE_CODE','FIRE_YEAR', 'LATITUDE', 'LONGITUDE','DISCOVERY_DATE','FIRE_SIZE','STATE']]\ntest3 = test[['STAT_CAUSE_CODE','FIRE_YEAR', 'LATITUDE', 'LONGITUDE','DISCOVERY_DATE','FIRE_SIZE','STATE']]\n#print(len(df3))\ndf3 = pd.concat([df3,pd.get_dummies(df3['STATE'], prefix='STATE')],axis=1).drop(['STATE'],axis=1)\ntest3 = pd.concat([test3,pd.get_dummies(test3['STATE'], prefix='STATE')],axis=1).drop(['STATE'],axis=1)\n#remove causes 9 and 13 from dataset\ndf3 = df3[(df3['STAT_CAUSE_CODE'] != 9) & (df3['STAT_CAUSE_CODE'] != 13)]\ntest3 = test3[(test3['STAT_CAUSE_CODE'] != 9) & (test3['STAT_CAUSE_CODE'] != 13)]\n#shuffle dataset\ndf3 = shuffle(df3)\ny = df3.iloc[:,0]\nprint(type(y))\nx = df3.iloc[:,1:]\ny_test = test3.iloc[:,0]\nX_test = test3.iloc[:,1:]\n#print(df.head())\n#print(df.STAT_CAUSE_CODE.unique())\n#df2 = pd.read_sql_query(\"SELECT DISTINCT STATE FROM 'Fires'\", conn)\n#print(df2)\nsize = len(y)\nsplit = int(size*0.77)\ny_train = y.iloc[:split]\nX_train = x.iloc[:split]\n#y_test = y.iloc[split:]\n#X_test = x.iloc[split:]\n\nLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)  \ny_pred=LR.predict(X_test)  \nprint(round(LR.score(X_test,y_test), 4))#0.3131\nprint(balanced_accuracy_score(y_test,y_pred))#0.0922\nprint(confusion_matrix(y_test,y_pred))\nprint(LR.classes_)\n\"\"\"\n[[  407     0     0     0 27273     0     0     0     0     0     0]\n [   35     0     0     0 14647     0     0     0     0     0     0]\n [    6     0     0     0  5213     0     0     0     0     0     0]\n [   15     0     0     0  7661     0     0     0     0     0     0]\n [   21     0     0     0 43008     0     0     0     0     0     0]\n [    5     0     0     0  3329     0     0     0     0     0     0]\n [   39     0     0     0 28053     0     0     0     0     0     0]\n [    3     0     0     0  6077     0     0     0     0     0     0]\n [    2     0     0     0  1055     0     0     0     0     0     0]\n [   13     0     0     0  1427     0     0     0     0     0     0]\n [    2     0     0     0   375     0     0     0     0     0     0]]\n \"\"\"\n\nRF = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0).fit(X_train, y_train)  \ny_pred=RF.predict(X_test)  \nprint(round(RF.score(X_test, y_test), 4)) #0.5127\nprint(balanced_accuracy_score(y_test, y_pred))#0.2299\nprint(confusion_matrix(y_test, y_pred))\n#0.3845 with no shuffle, and all categories, n_estimators = 1000, max_depth = 10, random_state = 0\n\n\"\"\"\nmlp = MLPClassifier()\nmlp.fit(X_train, y_train)\ny_pred=mlp.predict(X_test)\nprint(round(mlp.score(X_test,y_test),4))#0.3103\nprint(balanced_accuracy_score(y_test,y_pred))#0.090909\n#0.3087\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(confusion_matrix(y_test,y_pred))\n\"\"\"\n[[22436   737     0     0  3516   382   609     0     0     0     0]\n [ 2609  3607     0     6  7179   624   657     0     0     0     0]\n [ 1116   420     0     0  2914    52   717     0     0     0     0]\n [ 3984   434     0    47  2834    37   340     0     0     0     0]\n [ 3707   983     0     0 35181   189  2969     0     0     0     0]\n [  646    50     0     0  1373  1130   135     0     0     0     0]\n [ 1994  1299     0     3 16008    92  8696     0     0     0     0]\n [ 1036   560     0     0  3665   183   636     0     0     0     0]\n [  487     9     0     0   507     0    54     0     0     0     0]\n [  314   119     0     0   907     0   100     0     0     0     0]\n [   94     5     0     0   263     0    15     0     0     0     0]]\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#state, Contdate, na dropped, unnormalized, logistic regression\n\ndf4 = train[['STAT_CAUSE_CODE','FIRE_YEAR', 'LATITUDE', 'LONGITUDE','DISCOVERY_DATE','CONT_DATE','FIRE_SIZE','STATE']]\ntest4 = test[['STAT_CAUSE_CODE','FIRE_YEAR', 'LATITUDE', 'LONGITUDE','DISCOVERY_DATE','CONT_DATE','FIRE_SIZE','STATE']]\ndf4 = pd.concat([df4,pd.get_dummies(df4['STATE'], prefix='STATE')],axis=1).drop(['STATE'],axis=1)\ntest4 = pd.concat([test4,pd.get_dummies(test4['STATE'], prefix='STATE')],axis=1).drop(['STATE'],axis=1)\ndf4 = df4[(df4['STAT_CAUSE_CODE'] != 9) & (df4['STAT_CAUSE_CODE'] != 13)]\ntest4 = test4[(test4['STAT_CAUSE_CODE'] != 9) & (test4['STAT_CAUSE_CODE'] != 13)]\ndf4 = df4.dropna()\ntest4 = test4.dropna()\n\ndf4 = shuffle(df4)\ny = df4.iloc[:,0]\nx = df4.iloc[:,1:]\ny_test = test4.iloc[:,0]\nX_test = test4.iloc[:,1:]\n\nsize = len(y)\nsplit = int(size*0.77)\ny_train = y.iloc[:split]\nX_train = x.iloc[:split]\n\nLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)  \ny_pred=LR.predict(X_test)  \nprint(round(LR.score(X_test,y_test), 4))#0.3014\nprint(balanced_accuracy_score(y_test,y_pred))#0.0909\nprint(confusion_matrix(y_test,y_pred))\n\"\"\"\n[[22581     0     0     0     0     0     0     0     0     0     0]\n [ 5341     0     0     0     0     0     0     0     0     0     0]\n [ 2493     0     0     0     0     0     0     0     0     0     0]\n [ 5608     0     0     0     0     0     0     0     0     0     0]\n [18534     0     0     0     0     0     0     0     0     0     0]\n [  849     0     0     0     0     0     0     0     0     0     0]\n [14518     0     0     0     0     0     0     0     0     0     0]\n [ 2888     0     0     0     0     0     0     0     0     0     0]\n [  983     0     0     0     0     0     0     0     0     0     0]\n [  833     0     0     0     0     0     0     0     0     0     0]\n [  301     0     0     0     0     0     0     0     0     0     0]]\n\"\"\"\nprint(LR.classes_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#state, contdate, na dropped, normalized, logistic regression\n\nmean = df4.mean()\nmean.iloc[0]=0\ndrange = df4.max()-df4.min()\ndrange[0]=1\n\ndnorm = (df4-mean)/drange\ntnorm = (test4-mean)/drange\ndnorm.iloc[7:]=df4.iloc[7:]\ntnorm.iloc[7:]=test4.iloc[7:]\n\ny = dnorm.iloc[:,0]\nx = dnorm.iloc[:,1:]\ny_test = tnorm.iloc[:,0]\nX_test = tnorm.iloc[:,1:]\n\nsize = len(y)\nsplit = int(size*0.77)\ny_train = y.iloc[:split]\nX_train = x.iloc[:split]\n\nLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)  \ny_pred=LR.predict(X_test)  \nprint(round(LR.score(X_test,y_test), 4))#0.3014\nprint(balanced_accuracy_score(y_test,y_pred))#0.0909\nprint(confusion_matrix(y_test,y_pred))\n\"\"\"\n[[22581     0     0     0     0     0     0     0     0     0     0]\n [ 5341     0     0     0     0     0     0     0     0     0     0]\n [ 2493     0     0     0     0     0     0     0     0     0     0]\n [ 5608     0     0     0     0     0     0     0     0     0     0]\n [18530     0     0     0     2     0     0     0     0     0     2]\n [  849     0     0     0     0     0     0     0     0     0     0]\n [14517     0     0     0     1     0     0     0     0     0     0]\n [ 2888     0     0     0     0     0     0     0     0     0     0]\n [  983     0     0     0     0     0     0     0     0     0     0]\n [  833     0     0     0     0     0     0     0     0     0     0]\n [  301     0     0     0     0     0     0     0     0     0     0]]\n \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#state, contdate included, extra column, unnormalized, logistic regression\ndf5 = train[['STAT_CAUSE_CODE','FIRE_YEAR', 'LATITUDE', 'LONGITUDE','DISCOVERY_DATE','CONT_DATE','FIRE_SIZE','STATE']]\ntest5 = test[['STAT_CAUSE_CODE','FIRE_YEAR', 'LATITUDE', 'LONGITUDE','DISCOVERY_DATE','CONT_DATE','FIRE_SIZE','STATE']]\ndf5 = pd.concat([df5,pd.get_dummies(df5['STATE'], prefix='STATE')],axis=1).drop(['STATE'],axis=1)\ntest5 = pd.concat([test5,pd.get_dummies(test5['STATE'], prefix='STATE')],axis=1).drop(['STATE'],axis=1)\ndf5 = df5[(df5['STAT_CAUSE_CODE'] != 9) & (df5['STAT_CAUSE_CODE'] != 13)]\ntest5 = test5[(test5['STAT_CAUSE_CODE'] != 9) & (test5['STAT_CAUSE_CODE'] != 13)]\ndf5['burn_time'] = df5['CONT_DATE'] - df5['DISCOVERY_DATE']\ndf5['burn_time_notna'] = df5.burn_time.notna().astype(int)\ndf5 = df5.drop(['CONT_DATE','DISCOVERY_DATE'], axis = 1)\ntest5['burn_time'] = test5['CONT_DATE']-test5['DISCOVERY_DATE']\ntest5['burn_time_notna'] = test5.burn_time.notna().astype(int)\ntest5 = test5.drop(['CONT_DATE', 'DISCOVERY_DATE'], axis = 1)\ndf5 = df5.fillna(-1)\ntest5 = test5.fillna(-1)\nprint(df5.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(df5[df5.isna().any(axis=1)])\ny = df5.iloc[:,0]\nx = df5.iloc[:,1:]\ny_test = test5.iloc[:,0]\nX_test = test5.iloc[:,1:]\n\nsize = len(y)\nsplit = int(size*0.77)\ny_train = y.iloc[:split]\nX_train = x.iloc[:split]\n\nmlp = MLPClassifier()\nmlp.fit(X_train, y_train)\ny_pred=mlp.predict(X_test)\nprint(round(mlp.score(X_test,y_test),4))#0.4981\nprint(balanced_accuracy_score(y_test,y_pred))#0.2242\nprint(confusion_matrix(y_test,y_pred))\n#without discovery date\n\"\"\"\n[[21345   794     0     5  3177   941  1318   100     0     0     0]\n [ 2368  3632     0     6  6840   748   962   126     0     0     0]\n [  996   465     0     4  2734    75   915    30     0     0     0]\n [ 3810   471     0     4  2486    78   771    56     0     0     0]\n [ 3231  1194     1     9 33174   539  4690   191     0     0     0]\n [  806    54     0     0  1283   974   214     3     0     0     0]\n [ 2364  1404     0     4 14279   281  9705    54     0     1     0]\n [  914   613     0     0  3330   288   697   238     0     0     0]\n [  418     7     0     0   331     1   155   145     0     0     0]\n [  286    84     0     0   877     0   185     8     0     0     0]\n [   74     6     0     0   196     0    44    57     0     0     0]]\n\"\"\"\nLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial',max_iter=1000).fit(X_train, y_train)  \ny_pred=LR.predict(X_test)\n#first set without discovery date, second set with\nprint(round(LR.score(X_test,y_test), 4))#0.4311#3131\nprint(balanced_accuracy_score(y_test,y_pred))#0.1513#0.0922\nprint(confusion_matrix(y_test,y_pred))\n\"\"\"\n[[21160     2     0     0  6370     0   148     0     0     0     0]\n [ 5566     1     0     0  9066     0    49     0     0     0     0]\n [ 1499     1     0     0  3693     0    26     0     0     0     0]\n [ 4369     0     0     0  3276     0    31     0     0     0     0]\n [ 4517     0     0     0 38444     0    68     0     0     0     0]\n [  364     0     0     0  2961     0     9     0     0     0     0]\n [ 3488     0     0     0 24430     0   174     0     0     0     0]\n [ 1579     0     0     0  4473     0    28     0     0     0     0]\n [  492     0     0     0   564     0     1     0     0     0     0]\n [  377     0     0     0  1056     0     7     0     0     0     0]\n [  121     0     0     0   256     0     0     0     0     0     0]]\n\"\"\"\n\"\"\"\n[[  415     0     0     0 27265     0     0     0     0     0     0]\n [   36     0     0     0 14646     0     0     0     0     0     0]\n [    7     0     0     0  5212     0     0     0     0     0     0]\n [   15     0     0     0  7661     0     0     0     0     0     0]\n [   23     0     0     0 43006     0     0     0     0     0     0]\n [    6     0     0     0  3328     0     0     0     0     0     0]\n [   41     0     0     0 28051     0     0     0     0     0     0]\n [    3     0     0     0  6077     0     0     0     0     0     0]\n [    2     0     0     0  1055     0     0     0     0     0     0]\n [   14     0     0     0  1426     0     0     0     0     0     0]\n [    2     0     0     0   375     0     0     0     0     0     0]]\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#state, contdate, extra column, normalized, logistic regression\n\nmean = df5.mean()\nmean.iloc[0]=0\ndrange = df5.max()-df5.min()\ndrange[0]=1\n\ndnorm = (df5-mean)/drange\ntnorm = (test5-mean)/drange\ndnorm.iloc[5:-2]=df5.iloc[5:-2]\ntnorm.iloc[5:-2]=test5.iloc[5:-2]\n\ny = dnorm.iloc[:,0]\nx = dnorm.iloc[:,1:]\ny_test = tnorm.iloc[:,0]\nX_test = tnorm.iloc[:,1:]\n\nsize = len(y)\nsplit = int(size*0.77)\ny_train = y.iloc[:split]\nX_train = x.iloc[:split]\n\nmlp = MLPClassifier()\nmlp.fit(X_train, y_train)\ny_pred=mlp.predict(X_test)\nprint(round(mlp.score(X_test,y_test),4))#4986\nprint(balanced_accuracy_score(y_test,y_pred))#0.2188\nprint(confusion_matrix(y_test,y_pred))\n\"\"\"\n[[21577   734     0     3  3042   782  1367   175     0     0     0]\n [ 2376  3761     0     8  6674   512  1196   155     0     0     0]\n [  983   515     0     4  2708    30   945    34     0     0     0]\n [ 3784   497     0    14  2452    52   819    58     0     0     0]\n [ 3183  1322     0     9 32797   341  5101   276     0     0     0]\n [  889   294     0     1  1279   649   221     1     0     0     0]\n [ 2424  1383     0     1 14019   208  9989    68     0     0     0]\n [  946   669     0     3  3149   213   754   346     0     0     0]\n [  455     6     0     1   236     1   177   181     0     0     0]\n [  277    88     0     1   831     0   231    12     0     0     0]\n [   72     5     0     0   172     0    60    68     0     0     0]]\n\"\"\"\n\nLR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial',max_iter=1000).fit(X_train, y_train)  \ny_pred=LR.predict(X_test) \n#first set with discovery date\nprint(round(LR.score(X_test,y_test), 4))##0.3131\nprint(balanced_accuracy_score(y_test,y_pred))#0.0922\nprint(confusion_matrix(y_test,y_pred))\n\n\"\"\"\n[[  416     0     0     0 27264     0     0     0     0     0     0]\n [   36     0     0     0 14646     0     0     0     0     0     0]\n [    7     0     0     0  5212     0     0     0     0     0     0]\n [   16     0     0     0  7660     0     0     0     0     0     0]\n [   24     0     0     0 43004     0     0     0     0     0     1]\n [    6     0     0     0  3328     0     0     0     0     0     0]\n [   42     0     0     0 28050     0     0     0     0     0     0]\n [    3     0     0     0  6077     0     0     0     0     0     0]\n [    2     0     0     0  1055     0     0     0     0     0     0]\n [   14     0     0     0  1426     0     0     0     0     0     0]\n [    2     0     0     0   375     0     0     0     0     0     0]]\n\"\"\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}