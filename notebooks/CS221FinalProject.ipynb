{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS221FinalProject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtR3JbAuPlvz",
        "colab_type": "text"
      },
      "source": [
        "# Wildfire Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7zQv_GzR8EF",
        "colab_type": "text"
      },
      "source": [
        "First things first: Imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQkLfHV3NJVs",
        "colab_type": "code",
        "outputId": "6b36c5cf-e62e-442f-c9a3-00a15d86dbdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# In order to be able to read parquet files\n",
        "!pip install pyarrow\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.16.3)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB3T1FXUPzbz",
        "colab_type": "text"
      },
      "source": [
        "## Load the wildfire training data\n",
        "\n",
        "Let's read in the training data from its home in my AFS www directory. This can take a bit of time (30s to a minute or so)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0EnULrDORnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_parquet('http://web.stanford.edu/~sjespers/cs221/train-wildfires.parquet')\n",
        "\n",
        "# To load a smaller, more manageable sample of the training set, run this instead:\n",
        "# df = pd.read_parquet('http://web.stanford.edu/~sjespers/cs221/wildfires-sample.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP62c9nlmuxM",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning/preparation\n",
        "\n",
        "Here we prep the dataframe for input into keras/sklearn. First, we lowercase all column names, and we might as well drop the columns we don't care about."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTiN6RIDnllr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INTERESTING_COLS = \"\"\"\n",
        "fire_size\n",
        "fire_year\n",
        "discovery_date\n",
        "discovery_time\n",
        "stat_cause_code\n",
        "stat_cause_descr\n",
        "cont_date\n",
        "cont_doy\n",
        "cont_time\n",
        "latitude\n",
        "longitude\n",
        "state\n",
        "county\n",
        "fips_code\n",
        "nwcg_reporting_unit_id\n",
        "\"\"\".strip().split(\"\\n\")\n",
        "\n",
        "df.rename(columns={s: s.lower() for s in df.columns}, inplace=True)\n",
        "df.stat_cause_code = df.stat_cause_code.astype(int)\n",
        "df = df.filter(items=INTERESTING_COLS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNNgSTQhHkWy",
        "colab_type": "text"
      },
      "source": [
        "Now we drop codes 9 and 13, corresponding to miscellaneous and unknown causes, which are pretty useless."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7HTysN7HsB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[(df.stat_cause_code != 9) & (df.stat_cause_code != 13)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjta88sU_r0o",
        "colab_type": "text"
      },
      "source": [
        "At this point, it's interesting to see the distribution of the remaining causes. Note that debris burning is the clear front-runner:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAjCTqVA_yZx",
        "colab_type": "code",
        "outputId": "6804c7cb-4cdd-4d0c-d886-f02e79651a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "df.stat_cause_descr.value_counts().plot(kind='barh')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff3cc658fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAD8CAYAAAAIasE6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlVQc6rJ1CIAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFA6Lelenoai",
        "colab_type": "text"
      },
      "source": [
        "Now, we need to one-hot encode the categorical labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MFgWdS_T8QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_df = pd.get_dummies(df.stat_cause_descr)\n",
        "labels = label_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6-vCCmUos-R",
        "colab_type": "text"
      },
      "source": [
        "Let's handle the features next. First, we define a new feature, `burn_time`, in terms of two others, taking note of where it's not available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7LtCQm4j6S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['burn_time'] = df.cont_date - df.discovery_date\n",
        "df['burn_time_notna'] = df.burn_time.notna().astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnSHG8DJj7au",
        "colab_type": "text"
      },
      "source": [
        "Then, filtering to just the ones we care about:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F22-IHyoqs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FEATURE_COLS = \"\"\"\n",
        "fire_size\n",
        "fire_year\n",
        "burn_time\n",
        "burn_time_notna\n",
        "latitude\n",
        "longitude\n",
        "\"\"\".strip().split(\"\\n\")\n",
        "\n",
        "data = df.filter(items=FEATURE_COLS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSlGe3U7nfBH",
        "colab_type": "text"
      },
      "source": [
        "### Feature scaling\n",
        "\n",
        "MLP's are apparently rather sensitive to feature scaling, so we should normalize all features to within a similar range, e.g. (0, 1) or (-1, 1).\n",
        "\n",
        "In order to do this, we first check the ranges of the various columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf1JDAyrnoOf",
        "colab_type": "code",
        "outputId": "777e9e8f-28e0-40c6-d120-567923cbda8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fire_size</th>\n",
              "      <th>fire_year</th>\n",
              "      <th>burn_time</th>\n",
              "      <th>burn_time_notna</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.251271e+06</td>\n",
              "      <td>1.251271e+06</td>\n",
              "      <td>679291.000000</td>\n",
              "      <td>1.251271e+06</td>\n",
              "      <td>1.251271e+06</td>\n",
              "      <td>1.251271e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.425213e+01</td>\n",
              "      <td>2.003325e+03</td>\n",
              "      <td>1.275430</td>\n",
              "      <td>5.428808e-01</td>\n",
              "      <td>3.701755e+01</td>\n",
              "      <td>-9.581148e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.760037e+03</td>\n",
              "      <td>6.638181e+00</td>\n",
              "      <td>15.054777</td>\n",
              "      <td>4.981580e-01</td>\n",
              "      <td>5.840018e+00</td>\n",
              "      <td>1.571389e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.000000e-05</td>\n",
              "      <td>1.992000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.794492e+01</td>\n",
              "      <td>-1.733857e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000e-01</td>\n",
              "      <td>1.998000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.281042e+01</td>\n",
              "      <td>-1.098029e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.003000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>3.543330e+01</td>\n",
              "      <td>-9.146357e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000e+00</td>\n",
              "      <td>2.009000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>4.085033e+01</td>\n",
              "      <td>-8.273000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>6.069450e+05</td>\n",
              "      <td>2.015000e+03</td>\n",
              "      <td>4018.000000</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>7.033060e+01</td>\n",
              "      <td>-6.525694e+01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fire_size     fire_year  ...      latitude     longitude\n",
              "count  1.251271e+06  1.251271e+06  ...  1.251271e+06  1.251271e+06\n",
              "mean   8.425213e+01  2.003325e+03  ...  3.701755e+01 -9.581148e+01\n",
              "std    2.760037e+03  6.638181e+00  ...  5.840018e+00  1.571389e+01\n",
              "min    9.000000e-05  1.992000e+03  ...  1.794492e+01 -1.733857e+02\n",
              "25%    1.000000e-01  1.998000e+03  ...  3.281042e+01 -1.098029e+02\n",
              "50%    1.000000e+00  2.003000e+03  ...  3.543330e+01 -9.146357e+01\n",
              "75%    4.000000e+00  2.009000e+03  ...  4.085033e+01 -8.273000e+01\n",
              "max    6.069450e+05  2.015000e+03  ...  7.033060e+01 -6.525694e+01\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9rQANgfgZPD",
        "colab_type": "text"
      },
      "source": [
        "Then we can normalize and fill in the gaps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP9s__dmgZjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(df):\n",
        "  newdf = df.copy()\n",
        "  # fire_year is between 1992 and 2015\n",
        "  newdf.fire_year = (df.fire_year - 1992) / (2015 - 1992)\n",
        "  # fire_size is between 0 and ~100,000 (acres)\n",
        "  newdf.fire_size = 1. * df.fire_size / 100000\n",
        "  # burn_time is between 0 and ~5,000\n",
        "  newdf.burn_time = 1. * df.burn_time / 5000\n",
        "  # shove -1 into burn_time where we don't have it;\n",
        "  # the NN should pick up on this\n",
        "  newdf.burn_time.fillna(-1, inplace=True)\n",
        "  # latitude: take (-90, 90) -> (-1, 1)\n",
        "  newdf.latitude /= 90\n",
        "  # longitude: take (-180, 180) -> (-1, 1)\n",
        "  newdf.longitude /= 180\n",
        "  return newdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb88Kk-QEyCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized_data = normalize(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG-hbPTFH4M_",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the data just to make sure things are going basically as we would expect at this point:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZqMybOoH9U8",
        "colab_type": "code",
        "outputId": "384fb50a-0157-4f8b-cea4-f5eb0921774f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "normalized_data.sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fire_size</th>\n",
              "      <th>fire_year</th>\n",
              "      <th>burn_time</th>\n",
              "      <th>burn_time_notna</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OBJECTID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>840194</th>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.260870</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.387731</td>\n",
              "      <td>-0.481498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1039717</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.386297</td>\n",
              "      <td>-0.429537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>876380</th>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.368651</td>\n",
              "      <td>-0.467883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1536634</th>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.367602</td>\n",
              "      <td>-0.540724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290722</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.475315</td>\n",
              "      <td>-0.410770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149383</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.434830</td>\n",
              "      <td>-0.669907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133393</th>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.347826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.351593</td>\n",
              "      <td>-0.616213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1031051</th>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.404352</td>\n",
              "      <td>-0.427379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265108</th>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.480349</td>\n",
              "      <td>-0.569292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1110239</th>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.608696</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.438932</td>\n",
              "      <td>-0.674855</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          fire_size  fire_year  burn_time  burn_time_notna  latitude  longitude\n",
              "OBJECTID                                                                       \n",
              "840194     0.000005   0.260870       -1.0                0  0.387731  -0.481498\n",
              "1039717    0.000001   0.391304       -1.0                0  0.386297  -0.429537\n",
              "876380     0.000005   0.304348       -1.0                0  0.368651  -0.467883\n",
              "1536634    0.000003   0.739130       -1.0                0  0.367602  -0.540724\n",
              "1290722    0.000001   0.739130        0.0                1  0.475315  -0.410770\n",
              "149383     0.000001   0.434783        0.0                1  0.434830  -0.669907\n",
              "133393     0.000010   0.347826        0.0                1  0.351593  -0.616213\n",
              "1031051    0.000010   0.304348       -1.0                0  0.404352  -0.427379\n",
              "265108     0.000001   0.608696        0.0                1  0.480349  -0.569292\n",
              "1110239    0.000005   0.608696       -1.0                0  0.438932  -0.674855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvKH-9K0qNNa",
        "colab_type": "text"
      },
      "source": [
        "## Keras MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzUILjpLnppe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah0Mee1LnpJM",
        "colab_type": "text"
      },
      "source": [
        "Okay, let's set up a simple MLP for multiclass softmax classification:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIV1MCTfPR2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_dim=len(data.columns)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(labels.shape[1], activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWEkW1nzzUeE",
        "colab_type": "text"
      },
      "source": [
        "Time to fit the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDCl_WFbmr5M",
        "colab_type": "code",
        "outputId": "5666f8bb-2fd9-4c40-d5c9-429ba6bd882b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "history = model.fit(normalized_data.values, labels, epochs=5, batch_size=256, validation_split=0.222)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 973488 samples, validate on 277783 samples\n",
            "Epoch 1/5\n",
            "973488/973488 [==============================] - 18s 18us/step - loss: 1.4293 - acc: 0.5108 - val_loss: 1.4307 - val_acc: 0.5078\n",
            "Epoch 2/5\n",
            "973488/973488 [==============================] - 18s 18us/step - loss: 1.4271 - acc: 0.5112 - val_loss: 1.4257 - val_acc: 0.5105\n",
            "Epoch 3/5\n",
            "973488/973488 [==============================] - 18s 18us/step - loss: 1.4252 - acc: 0.5120 - val_loss: 1.4308 - val_acc: 0.5102\n",
            "Epoch 4/5\n",
            "973488/973488 [==============================] - 19s 19us/step - loss: 1.4228 - acc: 0.5127 - val_loss: 1.4242 - val_acc: 0.5112\n",
            "Epoch 5/5\n",
            "973488/973488 [==============================] - 18s 18us/step - loss: 1.4212 - acc: 0.5133 - val_loss: 1.4197 - val_acc: 0.5111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_8sDrPi9iWu",
        "colab_type": "text"
      },
      "source": [
        "We'll define a helper function for computing balanced accuracy now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlw35JGZ8Cya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "\n",
        "def balanced_accuracy(ytrue, ypred):\n",
        "  return sklearn.metrics.balanced_accuracy_score(\n",
        "      np.argmax(ytrue, axis=1),\n",
        "      np.argmax(ypred, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r47G10iD23Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_ypred = model.predict(normalized_data.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvILYbcP9504",
        "colab_type": "code",
        "outputId": "6cc40d45-cdd5-45d8-f77e-2b448767b036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "balanced_accuracy(labels, mlp_ypred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2512732529752906"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25OM4eHwA2Dv",
        "colab_type": "text"
      },
      "source": [
        "### Save the model\n",
        "\n",
        "I'd suggest downloading this locally, too, just to make sure that if this notebook dies on you, you still have your progress saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWeeEvGBA2aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('cs221-finalproj-initialmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShaUqk6TrW9g",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "It'd be nice to get a feel for how well the model is doing on each of the 11 categories. First, we need the predicted values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGs-O9gOnu9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk3sQeeTrVxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ypred = model.predict(normalized_data.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlIraK0Bwzi1",
        "colab_type": "code",
        "outputId": "6b00f402-a048-4c26-d02a-e9fcf0670abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "confusion_mtx = sklearn.metrics.confusion_matrix(\n",
        "    np.argmax(labels, axis=1),\n",
        "    np.argmax(ypred, axis=1))\n",
        "\n",
        "sns.set()\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(np.log(confusion_mtx + 1))#, annot=True, fmt=\".2f\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f47f60b3cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAJHCAYAAAByw0fcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg6EyXA2Faxn",
        "colab_type": "text"
      },
      "source": [
        "## Sklearn *k*-NN Oracle\n",
        "\n",
        "Here we run *k*-NN for the training data, for use as an oracle, a target for our MLP to shoot for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGzvJKRXFedz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V48tdtksvtC",
        "colab_type": "text"
      },
      "source": [
        "### *k* = 10\n",
        "\n",
        "*k* = 10 should give okay but not great results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD1N8b2cF2zP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_70e8ZpyIdKq",
        "colab_type": "code",
        "outputId": "e6661390-9f17-45e0-dca9-c9fff97d31e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "knn.fit(data, labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQRSXKOBIePi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = knn.predict(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl9bCkscz9_S",
        "colab_type": "text"
      },
      "source": [
        "Let's take a peek at the balanced accuracy for `k=10`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAO2C9yNs6Rn",
        "colab_type": "code",
        "outputId": "653f8ad4-6aea-4db3-9fbd-d3b9ada2202c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "balanced_accuracy(labels, y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30348264481573406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9b4ryMn0Dtu",
        "colab_type": "text"
      },
      "source": [
        "### *k* = 5\n",
        "\n",
        "*k* = 5 should be a little better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld7PEUzRMb8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn2 = KNeighborsClassifier(n_neighbors=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7truY8AkyIdy",
        "colab_type": "code",
        "outputId": "7d06df38-eda0-4604-fe07-1819124060da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "knn2.fit(data, labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EusUwtw5wQwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ypred2 = knn2.predict(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1PG_spky8BC",
        "colab_type": "code",
        "outputId": "8dac1710-18d4-4af0-a4f7-f3ef0e028454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "balanced_accuracy(labels, ypred2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40252320082885223"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvTzMjmH0RPn",
        "colab_type": "text"
      },
      "source": [
        "### *k* = 3\n",
        "\n",
        "Now we're starting to approach *k* = 1, which is by definition 100% accurate, so we expect to continue to see the accuracy rise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVcy-nOoNvXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn3 = KNeighborsClassifier(n_neighbors=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thzBDRLjPeXZ",
        "colab_type": "code",
        "outputId": "062a04a7-844f-4aff-f30a-ff1a5d7958ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "knn3.fit(data, labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-h4JqS8Pfbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred3 = knn3.predict(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFqHFbSnH_6y",
        "colab_type": "code",
        "outputId": "8773f600-d781-4ac7-d57d-3ab2dbb9239e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "balanced_accuracy(labels, y_pred3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5000034153736788"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fyt2NdliAq9i",
        "colab_type": "text"
      },
      "source": [
        "## Sklearn logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItH9GS-wAumm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Foip7AZuBZzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logistic_model = LogisticRegressionCV(cv=5, solver='lbfgs', multi_class='multinomial')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBefJqrbEiuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_no_na = data.dropna()\n",
        "no_na_labels = df.stat_cause_code[data_no_na.index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOgyN332CrxJ",
        "colab_type": "text"
      },
      "source": [
        "In contrast to Keras, which likes the multiclass output labels to be expressed as vectors (with as many entries as categories), sklearn expects scalar labels, hence the invocation of `np.argmax`. Let's fit the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZpHT3HxBl4K",
        "colab_type": "code",
        "outputId": "917a1ca7-6c34-4de4-b497-96233628fade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "source": [
        "logistic_model.fit(data_no_na, no_na_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-007b884c6470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogistic_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_no_na\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_na_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, np.argmax(labels, axis=1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2083\u001b[0m                       \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m                       )\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             for l1_ratio in l1_ratios_)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         max_squared_sum=max_squared_sum, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_multi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    342\u001b[0m     grad = np.zeros((n_classes, n_features + bool(fit_intercept)),\n\u001b[1;32m    343\u001b[0m                     dtype=X.dtype)\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msquared_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# suppress warnings about log of zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I3Jeq2uBsjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}