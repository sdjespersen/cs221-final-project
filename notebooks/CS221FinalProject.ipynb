{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS221FinalProject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtR3JbAuPlvz",
        "colab_type": "text"
      },
      "source": [
        "# Wildfire Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7zQv_GzR8EF",
        "colab_type": "text"
      },
      "source": [
        "First things first: Imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQkLfHV3NJVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In order to be able to read parquet files\n",
        "!pip install pyarrow\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB3T1FXUPzbz",
        "colab_type": "text"
      },
      "source": [
        "## Load the wildfire training data\n",
        "\n",
        "Let's read in the training data from its home in my AFS www directory. This can take a bit of time (30s to a minute or so)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0EnULrDORnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_parquet('http://web.stanford.edu/~sjespers/cs221/train-wildfires.parquet')\n",
        "\n",
        "# To load a smaller, more manageable sample of the training set, run this instead:\n",
        "# df = pd.read_parquet('http://web.stanford.edu/~sjespers/cs221/wildfires-sample.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP62c9nlmuxM",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning/preparation\n",
        "\n",
        "Here we prep the dataframe for input into keras/sklearn. First, we lowercase all column names, and we might as well drop the columns we don't care about."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTiN6RIDnllr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INTERESTING_COLS = \"\"\"\n",
        "fire_size\n",
        "fire_year\n",
        "discovery_date\n",
        "discovery_time\n",
        "stat_cause_code\n",
        "stat_cause_descr\n",
        "cont_date\n",
        "cont_doy\n",
        "cont_time\n",
        "latitude\n",
        "longitude\n",
        "state\n",
        "county\n",
        "fips_code\n",
        "nwcg_reporting_unit_id\n",
        "\"\"\".strip().split(\"\\n\")\n",
        "\n",
        "df.rename(columns={s: s.lower() for s in df.columns}, inplace=True)\n",
        "df.stat_cause_code = df.stat_cause_code.astype(int)\n",
        "df = df.filter(items=INTERESTING_COLS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNNgSTQhHkWy",
        "colab_type": "text"
      },
      "source": [
        "Now we drop codes 9 and 13, corresponding to miscellaneous and unknown causes, which are pretty useless."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7HTysN7HsB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[(df.stat_cause_code != 9) & (df.stat_cause_code != 13)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjta88sU_r0o",
        "colab_type": "text"
      },
      "source": [
        "At this point, it's interesting to see the distribution of the remaining causes. Note that debris burning is the clear front-runner:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAjCTqVA_yZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.stat_cause_descr.value_counts().plot(kind='barh')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFA6Lelenoai",
        "colab_type": "text"
      },
      "source": [
        "Now, we need to one-hot encode the categorical labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MFgWdS_T8QX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_df = pd.get_dummies(df.stat_cause_descr)\n",
        "labels = label_df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6-vCCmUos-R",
        "colab_type": "text"
      },
      "source": [
        "Let's handle the features next. First, we define a new feature, `burn_time`, in terms of two others, taking note of where it's not available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7LtCQm4j6S2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['burn_time'] = df.cont_date - df.discovery_date\n",
        "df['burn_time_notna'] = df.burn_time.notna().astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnSHG8DJj7au",
        "colab_type": "text"
      },
      "source": [
        "Then, filtering to just the ones we care about:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_F22-IHyoqs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FEATURE_COLS = \"\"\"\n",
        "fire_size\n",
        "fire_year\n",
        "burn_time\n",
        "burn_time_notna\n",
        "latitude\n",
        "longitude\n",
        "\"\"\".strip().split(\"\\n\")\n",
        "\n",
        "data = df.filter(items=FEATURE_COLS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSlGe3U7nfBH",
        "colab_type": "text"
      },
      "source": [
        "### Feature scaling\n",
        "\n",
        "MLP's are apparently rather sensitive to feature scaling, so we should normalize all features to within a similar range, e.g. (0, 1) or (-1, 1).\n",
        "\n",
        "In order to do this, we first check the ranges of the various columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf1JDAyrnoOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9rQANgfgZPD",
        "colab_type": "text"
      },
      "source": [
        "Then we can normalize and fill in the gaps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP9s__dmgZjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(df):\n",
        "  newdf = df.copy()\n",
        "  # fire_year is between 1992 and 2015\n",
        "  newdf.fire_year = (df.fire_year - 1992) / (2015 - 1992)\n",
        "  # fire_size is between 0 and ~100,000 (acres)\n",
        "  newdf.fire_size = 1. * df.fire_size / 100000\n",
        "  # burn_time is between 0 and ~5,000\n",
        "  newdf.burn_time = 1. * df.burn_time / 5000\n",
        "  # shove -1 into burn_time where we don't have it;\n",
        "  # the NN should pick up on this\n",
        "  newdf.burn_time.fillna(-1, inplace=True)\n",
        "  # latitude: take (-90, 90) -> (-1, 1)\n",
        "  newdf.latitude /= 90\n",
        "  # longitude: take (-180, 180) -> (-1, 1)\n",
        "  newdf.longitude /= 180\n",
        "  return newdf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb88Kk-QEyCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized_data = normalize(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG-hbPTFH4M_",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the data just to make sure things are going basically as we would expect at this point:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZqMybOoH9U8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized_data.sample(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvKH-9K0qNNa",
        "colab_type": "text"
      },
      "source": [
        "## Keras MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzUILjpLnppe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah0Mee1LnpJM",
        "colab_type": "text"
      },
      "source": [
        "Okay, let's set up a simple MLP for multiclass softmax classification:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIV1MCTfPR2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_dim=len(data.columns)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(labels.shape[1], activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWEkW1nzzUeE",
        "colab_type": "text"
      },
      "source": [
        "Time to fit the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDCl_WFbmr5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(normalized_data.values, labels, epochs=5, batch_size=256, validation_split=0.222)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_8sDrPi9iWu",
        "colab_type": "text"
      },
      "source": [
        "We'll define a helper function for computing balanced accuracy now:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlw35JGZ8Cya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "\n",
        "def balanced_accuracy(ytrue, ypred):\n",
        "  return sklearn.metrics.balanced_accuracy_score(\n",
        "      np.argmax(ytrue, axis=1),\n",
        "      np.argmax(ypred, axis=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r47G10iD23Nw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp_ypred = model.predict(normalized_data.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvILYbcP9504",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "balanced_accuracy(labels, mlp_ypred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25OM4eHwA2Dv",
        "colab_type": "text"
      },
      "source": [
        "### Save the model\n",
        "\n",
        "I'd suggest downloading this locally, too, just to make sure that if this notebook dies on you, you still have your progress saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWeeEvGBA2aG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('cs221-finalproj-initialmodel.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShaUqk6TrW9g",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "It'd be nice to get a feel for how well the model is doing on each of the 11 categories. First, we need the predicted values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGs-O9gOnu9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk3sQeeTrVxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ypred = model.predict(normalized_data.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlIraK0Bwzi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "confusion_mtx = sklearn.metrics.confusion_matrix(\n",
        "    np.argmax(labels, axis=1),\n",
        "    np.argmax(ypred, axis=1))\n",
        "\n",
        "sns.set()\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(np.log(confusion_mtx + 1))#, annot=True, fmt=\".2f\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg6EyXA2Faxn",
        "colab_type": "text"
      },
      "source": [
        "## Sklearn *k*-NN Oracle\n",
        "\n",
        "Here we run *k*-NN for the training data, for use as an oracle, a target for our MLP to shoot for."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGzvJKRXFedz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V48tdtksvtC",
        "colab_type": "text"
      },
      "source": [
        "### *k* = 10\n",
        "\n",
        "*k* = 10 should give okay but not great results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD1N8b2cF2zP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_70e8ZpyIdKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn.fit(data, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQRSXKOBIePi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = knn.predict(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl9bCkscz9_S",
        "colab_type": "text"
      },
      "source": [
        "Let's take a peek at the balanced accuracy for `k=10`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAO2C9yNs6Rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "balanced_accuracy(labels, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9b4ryMn0Dtu",
        "colab_type": "text"
      },
      "source": [
        "### *k* = 5\n",
        "\n",
        "*k* = 5 should be a little better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld7PEUzRMb8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn2 = KNeighborsClassifier(n_neighbors=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7truY8AkyIdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn2.fit(data, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EusUwtw5wQwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ypred2 = knn2.predict(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1PG_spky8BC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "balanced_accuracy(labels, ypred2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvTzMjmH0RPn",
        "colab_type": "text"
      },
      "source": [
        "### *k* = 3\n",
        "\n",
        "Now we're starting to approach *k* = 1, which is by definition 100% accurate, so we expect to continue to see the accuracy rise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVcy-nOoNvXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn3 = KNeighborsClassifier(n_neighbors=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thzBDRLjPeXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn3.fit(data, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-h4JqS8Pfbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred3 = knn3.predict(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFqHFbSnH_6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "balanced_accuracy(labels, y_pred3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fyt2NdliAq9i",
        "colab_type": "text"
      },
      "source": [
        "## Sklearn logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItH9GS-wAumm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Foip7AZuBZzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logistic_model = LogisticRegressionCV(cv=5, solver='lbfgs', multi_class='multinomial')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBefJqrbEiuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_no_na = data.dropna()\n",
        "no_na_labels = df.stat_cause_code[data_no_na.index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOgyN332CrxJ",
        "colab_type": "text"
      },
      "source": [
        "In contrast to Keras, which likes the multiclass output labels to be expressed as vectors (with as many entries as categories), sklearn expects scalar labels, hence the invocation of `np.argmax`. Let's fit the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZpHT3HxBl4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logistic_model.fit(data_no_na, no_na_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I3Jeq2uBsjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}